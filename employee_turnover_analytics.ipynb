{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn scikit-learn imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Perform data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"HR_comma_sep.csv\")\n",
    "\n",
    "# get head rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather basic information about the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather descriptive statistics about the data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "df= df.rename(columns={\"average_montly_hours\":\"average_monthly_hours\",\"Work_accident\":\"work_accident\",\"sales\":\"department\",\"number_project\":\"number_of_projects\",\"time_spend_company\":\"years_with_company\",\"promotion_last_5years\":\"promotions_in_last_5_years\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new columns\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get duplicated rows\n",
    "duplicated_rows = df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numerical features\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "print(\"Numerical Features:\")\n",
    "print(df_numeric.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using IQR for numerical columns\n",
    "def detect_outliers(data, col):\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[col] > upper_bound) | (data[col] < lower_bound)]\n",
    "    return outliers\n",
    "\n",
    "\n",
    "#outlier columns\n",
    "outlier_cols=[\"satisfaction_level\",\"average_monthly_hours\",\"years_with_company\", \"number_of_projects\"]\n",
    "\n",
    "df_outliers= df_numeric[outlier_cols]\n",
    "outliers = {}\n",
    "for col in df_outliers:\n",
    "    outliers[col] = detect_outliers(df_numeric, col)\n",
    "    print(f'No of outliers for {col}', len(outliers[col]))\n",
    "\n",
    "\n",
    "# Plot boxplots for each numerical column\n",
    "for col in df_outliers:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot for {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_left_years_with_company= outliers['years_with_company'][outliers['years_with_company']['left']==1]\n",
    "\n",
    "len(outliers_left_years_with_company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "Most employees tend to leave or have shorter tenures (~4 years), while a there are few employees have been retained for significantly longer periods(>6 years)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "heatmap = sns.heatmap(df_numeric.corr(), vmin=-1, vmax=1, annot=True, cmap=sns.color_palette(\"vlag\", as_cmap=True))\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':14}, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: \n",
    "\n",
    "The correlation heatmap suggests that the number of projects, monthly hours, and evaluation scores all have some positive correlation with each other, and whether an employee leaves is negatively correlated with their satisfaction level.\n",
    "\n",
    "1) The employees with low satisfaction level are most likely and tend to leave (negative correlation  -0.39 )\n",
    "2) The Average monthly hours increases with number of projects the employee worked on (positive correaltion 0.42)\n",
    "3) The employees with higher evaluation score are assigned with more projects( positive corelation 0.35)\n",
    "4) The number of projects is not a significant factor in predicting employee turnover(0.024)\n",
    "5) The employees working for longer years with company, has a medium chance of leaving(0.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plot for satisfaction level\n",
    "\n",
    "satisfaction_level_stay = df_numeric[df_numeric['left']==0]['satisfaction_level']\n",
    "satisfaction_level_left = df_numeric[df_numeric['left']==1]['satisfaction_level']\n",
    "\n",
    "sns.histplot(data=df_numeric, x='satisfaction_level', hue='left', multiple='dodge',kde=True,bins=10)\n",
    "\n",
    "# sns.histplot(df_numeric['satisfaction_level'], kde=True,bins=30)\n",
    "plt.title('Distribution of Employee Satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plot for last_evaluation level\n",
    "last_evaluation_stay = df_numeric[df_numeric['left']==0]['last_evaluation']\n",
    "last_evaluation_left = df_numeric[df_numeric['left']==1]['last_evaluation']\n",
    "\n",
    "sns.histplot(data=df_numeric, x='last_evaluation', hue='left', multiple='dodge',kde=True,bins=10)\n",
    "\n",
    "# sns.histplot(df_numeric['satisfaction_level'], kde=True,bins=30)\n",
    "# plt.title('Distribution of Employee Satisfaction')\n",
    "# plt.show()\n",
    "# sns.histplot(df_numeric['last_evaluation'], kde=True,bins=30)\n",
    "plt.title('Distribution of Employee Last Evaluation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plot for last_evaluation level\n",
    "average_monthly_hours_stay = df_numeric[df_numeric['left']==0]['average_monthly_hours']\n",
    "average_monthly_hours_left = df_numeric[df_numeric['left']==1]['average_monthly_hours']\n",
    "\n",
    "sns.histplot(data=df_numeric, x='average_monthly_hours', hue='left', multiple='dodge',kde=False,bins=20)\n",
    "\n",
    "# sns.histplot(df_numeric['satisfaction_level'], kde=True,bins=30)\n",
    "# plt.title('Distribution of Employee Satisfaction')\n",
    "# plt.show()\n",
    "# sns.histplot(df_numeric['last_evaluation'], kde=True,bins=30)\n",
    "plt.title('Distribution of Employee average_monthly_hours')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot to compare the number of projects between employees who left and those who stayed\n",
    "no_of_projects_stay = df_numeric[df_numeric['left']==0]['number_of_projects']\n",
    "no_of_projects_left = df_numeric[df_numeric['left']==1]['number_of_projects']\n",
    "\n",
    "sns.histplot(data=df_numeric, x='number_of_projects', hue='left', multiple='dodge',kde=False,bins=10)\n",
    "\n",
    "plt.title('Employee Project Count: Left vs Stayed')\n",
    "plt.xlabel('Number of Projects')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation from distribution plots\n",
    "\n",
    "1) Again the employees with low satisfaction score are tend to leave\n",
    "2) The large distibution of employee leaving with low evaluation score and lesser number of average monthly hours, suggests that might have been asked to leave the company\n",
    "3) The prominent number of employee leaving with high last evaluation score, may be because of assigning larger number of projects causing burnout due to working for longer monthly average times\n",
    "4) The most optimal projects to be given are between 3 or 4 Projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_columns= [\"satisfaction_level\", \"last_evaluation\"]\n",
    "df_left = df_numeric[df_numeric['left'] == 1]\n",
    "\n",
    "clustering_data = df_left[clustered_columns]\n",
    "\n",
    "clustering_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=123)\n",
    "clusters = kmeans.fit_predict(clustering_data)\n",
    "\n",
    "# Add the cluster labels to the original dataframe\n",
    "df_left['cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clustering results\n",
    "sns.scatterplot(x='satisfaction_level', y='last_evaluation', hue='cluster', data=df_left, palette='viridis', s=100)\n",
    "plt.title('K-means Clustering of Employees Who Left')\n",
    "plt.xlabel('Satisfaction Level')\n",
    "plt.ylabel('Last Evaluation')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering Analysis\n",
    "\n",
    "Cluster-0 - Purple(Low-Satisfaction(<0.3) and High Last Evaluation (>0.75 ))\n",
    "1) Indicates that the employees are not satisfied even though they are highest performers, may be because of high burnout or not valued\n",
    "\n",
    "Cluster-1- Blue (Moderate- Satisfaction(Between 0.3 and 0.6) and Low Last Evaluation(<0.6))\n",
    "1) Indicates they are satisfied but lack performance, introducing performance improvement plans can make them more productive\n",
    "\n",
    "\n",
    "Cluster-2- Yellow (High-Satisfaction Level(> 0.7) and High Last Evaluation(>0.8))\n",
    "1) Indicates they are the most productive employees and are also satisfied, but they might have left because of getting better opportunites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies=  pd.get_dummies(df, columns= categorical_columns, drop_first=True)\n",
    "df_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_dummies.drop('left',axis=1)\n",
    "y = df_dummies['left']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=123)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Cross fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train the models and make predictions\n",
    "predictions_train = {}\n",
    "predictions_test={}\n",
    "probs_train = {}\n",
    "probs_test={}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    # Apply 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Display the cross-validation scores\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    print(f'{model_name} -', cv_scores, mean_cv_score)\n",
    "\n",
    "    predictions_train[model_name] = model.predict(X_train)\n",
    "    predictions_test[model_name]=model.predict(X_test)\n",
    "    probs_train[model_name] = model.predict_proba(X_train)[:, 1]\n",
    "    probs_test[model_name] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Best Model with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification reports and evaluate models\n",
    "for model_name in models:\n",
    "    print(f'Classification Report for {model_name} -  Train:\\n')\n",
    "    print(classification_report(y_train, predictions_train[model_name]))\n",
    "    roc_auc = roc_auc_score(y_train, probs_train[model_name])\n",
    "    print(f'ROC AUC for {model_name} - Train: {roc_auc:.2f}\\n')\n",
    "\n",
    "    print(f'Classification Report for {model_name} -  Test:\\n')\n",
    "    print(classification_report(y_test, predictions_test[model_name]))\n",
    "    roc_auc = roc_auc_score(y_test, probs_test[model_name])\n",
    "    print(f'ROC AUC for {model_name}- Test: {roc_auc:.2f}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (22,8))\n",
    "\n",
    "# Plot ROC curves\n",
    "for model_name in models:\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, probs_train[model_name])\n",
    "    auc = roc_auc_score(y_train, probs_train[model_name])\n",
    "    ax[0].plot(fpr_train, tpr_train, label=f'{model_name} (AUC = {auc:.2f})')\n",
    "\n",
    "    fpr_test, tpr_test, _ = roc_curve(y_test, probs_test[model_name])\n",
    "    auc = roc_auc_score(y_test, probs_test[model_name])\n",
    "    ax[1].plot(fpr_test, tpr_test, label=f'{model_name} (AUC = {auc:.2f})')\n",
    "\n",
    "\n",
    "ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "ax[0].set_title('ROC Curve (Train Set)')\n",
    "ax[0].set_xlabel('False Positive Rate')\n",
    "ax[0].set_ylabel('True Positive Rate')\n",
    "ax[0].legend(loc='lower right')\n",
    "\n",
    "\n",
    "\n",
    "ax[1].plot([0, 1], [0, 1], 'k--')\n",
    "ax[1].set_title('ROC Curve (Test Set)')\n",
    "ax[1].set_xlabel('False Positive Rate')\n",
    "ax[1].set_ylabel('True Positive Rate')\n",
    "ax[1].legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "\n",
    "for model_name in models:\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (22,8))\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, predictions_train[model_name])\n",
    "    cm_test=confusion_matrix(y_test,predictions_test[model_name])\n",
    "    sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', xticklabels=['Stayed', 'Left'], yticklabels=['Stayed', 'Left'],ax=ax[0])\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d',  xticklabels=['Stayed', 'Left'], yticklabels=['Stayed', 'Left'],ax=ax[1])\n",
    "\n",
    "    ax[0].set_title(f'Confusion Matrix for {model_name} - Train')\n",
    "    ax[0].set_xlabel('Predicted')\n",
    "    ax[0].set_ylabel('Actual')\n",
    "\n",
    "    ax[1].set_title(f'Confusion Matrix for {model_name} - Test')\n",
    "    ax[1].set_xlabel('Predicted')\n",
    "    ax[1].set_ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall or precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to identify employees who are likely to leave so that the company can take proactive retention measures.\n",
    "Recall ensures that the model correctly identifies most of the employees who are likely to leave (left = 1), minimizing false negatives (employees who leave but were predicted to stay)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above classification report,  we can identify that RandomForest is the best model based on recall\n",
    "\n",
    "model = models['Random Forest']  # Assuming Random Forest is the best model\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "df_test = X_test.copy()\n",
    "df_test['left_prob'] = y_test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retention_strategy(prob):\n",
    "    if prob < 0.20:\n",
    "        return 'Safe Zone (Green)'\n",
    "    elif prob < 0.60:\n",
    "        return 'Low-Risk Zone (Yellow)'\n",
    "    elif prob < 0.90:\n",
    "        return 'Medium-Risk Zone (Orange)'\n",
    "    else:\n",
    "        return 'High-Risk Zone (Red)'\n",
    "\n",
    "df_test['retention_zone'] = df_test['left_prob'].apply(retention_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
